{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agcorreas/KNN_TP/blob/main/TP_2_Metodos_Numericos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I415TUVQ6wk"
      },
      "source": [
        "# TP 2 - Métodos Numéricos\n",
        "## Grupo 11\n",
        "\n",
        "### Introducción\n",
        "Se recomienda ejecutar el notebook en el entorno de Google Colab para poder replicar los resultados obtenidos.\n",
        "\n",
        "<!--El notebook está ordenado por consigna por lo que pueden haber bloques de código dependiendo de alguno definido anteriormente. Se recomienda ejecutar todo el notebook la primera vez y luego ir descomentando los métodos de test para ir probando cada punto.-->\n",
        "\n",
        "El notebook está divido entre las secciones de la consigna:\n",
        "- KNN\n",
        "- Método de la potencia\n",
        "- Convergencia del Método de la potencia\n",
        "\n",
        "### KNN\n",
        "\n",
        "La sección de KNN tiene la implementación del algoritmo de K-Nearest Neighbors y la función `exactitud(k, X_train, y_train, X_dev, y_dev)` que dados los datos de los `k` vecinos a utilizar, y los conjuntos de datos de entrenaentramientomiento (`X_train, y_train`) y de prueba (`X_dev, y_dev`) calcula el porcentaje de exactitud de la implementación.\n",
        "\n",
        "### Método de la potencia\n",
        "\n",
        "La sección del Método de la potencia contiene la busqueda de los hiper parametros que maximizan el porcetaje de exactitud para una partición de los datos de entrenamiento en la función `cross_validation_autovectores()`. También se incluye la comparación contra el conjunto total de entrenamiento.\n",
        "La función `PCA(C)` toma una matriz `C` y calcula sus autovectores utilizando el método de la potencia programado utilizando `eigen`.\n",
        "\n",
        "### Convergencia del Método de la potencia\n",
        "\n",
        "En esta sección se calcularemos el resultado de aplicar método de la potencia con matrices Householder aleatorias y el error cometido en base a un parametro _epsilon_.\n",
        "La función `test_error()` genera los datos necesarios para graficar el promedio del error y el desvio estandar del mismo como también para el gráfico de cantidad de iteraciones necesarias para generar los autovalores utilizando el método de la potencia para cada _epsilon_.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzj-5O4__1Hw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats as st\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jxYXgFXygEF"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PyUieTcwxBf",
        "outputId": "4b70dd66-9ecf-4a8d-aaa0-ea7b02d573d4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-22 04:51:03--  https://www.dropbox.com/scl/fi/v6qfj1ktarocr8sl02r8k/datos.zip?rlkey=2u060s5619gvcvnnnhq93rn4e\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com/cd/0/inline/Ct--tTYR_06looClybB8aN1YiL2my7LCMd8EMh_UZ1q5LMdRAo9NGqvDoPhDwvn4yP8THfTx9wucG7_KJqYXLiVX0qp-G6l6XJspGiVvAv2MvAjuGbNOwLJJJCEvYH-Z2sLPA7Fb3Fw2aLEtE5JmYHy3/file# [following]\n",
            "--2025-07-22 04:51:04--  https://uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com/cd/0/inline/Ct--tTYR_06looClybB8aN1YiL2my7LCMd8EMh_UZ1q5LMdRAo9NGqvDoPhDwvn4yP8THfTx9wucG7_KJqYXLiVX0qp-G6l6XJspGiVvAv2MvAjuGbNOwLJJJCEvYH-Z2sLPA7Fb3Fw2aLEtE5JmYHy3/file\n",
            "Resolving uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com (uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com (uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Ct9NXXNDBqQF76vSwfAWrcsqaRN-j_4G6IKRrtHDQuNP1UzP-_Ob4j9ZxPc1iZBIpVI3EkaCv7tWakRw8I-sOnY9Xgdp6nFuYKSnLVLhZKjb5jBDP4nApOp4UnzRQQQI6ay1tcd3YdnL7nPb-YGAFDMMRFVBVbb2u3XLkllNnWFi7-4YFKfkDacvV3H6BfoM4qMY-mLwdHXyWl_67I9znh_rm01S85Y-QHAgsUzqF_9TyjvrX5e1Bs1RwIvjD8Oi7fPByPqvbPQz0yJFJgFt4nvbR_E-D5Lx2a1qJ6xTJ6qjAw0PGGAxrmMvW9WR9I9cUzvRMV_Cd7--RcLCW0CC9jvJOw8aAqkBZXrU16na18pR7TiD3_9i9brZL_s2mdEAK9o/file [following]\n",
            "--2025-07-22 04:51:04--  https://uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com/cd/0/inline2/Ct9NXXNDBqQF76vSwfAWrcsqaRN-j_4G6IKRrtHDQuNP1UzP-_Ob4j9ZxPc1iZBIpVI3EkaCv7tWakRw8I-sOnY9Xgdp6nFuYKSnLVLhZKjb5jBDP4nApOp4UnzRQQQI6ay1tcd3YdnL7nPb-YGAFDMMRFVBVbb2u3XLkllNnWFi7-4YFKfkDacvV3H6BfoM4qMY-mLwdHXyWl_67I9znh_rm01S85Y-QHAgsUzqF_9TyjvrX5e1Bs1RwIvjD8Oi7fPByPqvbPQz0yJFJgFt4nvbR_E-D5Lx2a1qJ6xTJ6qjAw0PGGAxrmMvW9WR9I9cUzvRMV_Cd7--RcLCW0CC9jvJOw8aAqkBZXrU16na18pR7TiD3_9i9brZL_s2mdEAK9o/file\n",
            "Reusing existing connection to uc72a7a9e51f64f8642210756096.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4665079 (4.4M) [application/zip]\n",
            "Saving to: ‘datos.zip’\n",
            "\n",
            "datos.zip           100%[===================>]   4.45M  23.1MB/s    in 0.2s    \n",
            "\n",
            "2025-07-22 04:51:05 (23.1 MB/s) - ‘datos.zip’ saved [4665079/4665079]\n",
            "\n",
            "Archive:  datos.zip\n",
            "replace datos/X_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: datos/X_train.csv       \n",
            "replace datos/X_test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: datos/X_test.csv        \n",
            "replace datos/y_test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: datos/y_test.csv        \n",
            "replace datos/y_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: datos/y_train.csv       \n"
          ]
        }
      ],
      "source": [
        "!wget -O datos.zip https://www.dropbox.com/scl/fi/v6qfj1ktarocr8sl02r8k/datos.zip?rlkey=2u060s5619gvcvnnnhq93rn4e&st=jy3dah88&dl=1\n",
        "!unzip datos.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrr0rVRewcDz",
        "outputId": "75cb337b-bf8e-4cc8-e848-3dff972cf045"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 784), (5000,), (500, 784), (500,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "\n",
        "class_names = [\"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\"\n",
        "]\n",
        "\n",
        "X_train = np.loadtxt(\"datos/X_train.csv\", delimiter=\",\")\n",
        "y_train = np.loadtxt(\"datos/y_train.csv\", delimiter=\",\").astype(int)\n",
        "X_test = np.loadtxt(\"datos/X_test.csv\", delimiter=\",\")\n",
        "y_test = np.loadtxt(\"datos/y_test.csv\", delimiter=\",\").astype(int)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M264dAYpDG15",
        "outputId": "de701abf-6eb4-45a1-97f3-354a62a0f19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8196392785571143\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "def distancia(X):\n",
        "  Y = copy.copy(X)\n",
        "  media_por_columna = np.mean(Y,axis = 1) #! Esto calcula la media por fila\n",
        "  Y = Y - media_por_columna.reshape((Y.shape[0],1))\n",
        "  Y_norma = np.linalg.norm(Y,axis=1,keepdims=True)\n",
        "  Y = Y / Y_norma\n",
        "  Z = Y @ Y.T\n",
        "  # unos = np.full((len(Z),len(Z)),1)\n",
        "  dist = 1 - Z\n",
        "  # print(dist.shape)\n",
        "  return dist\n",
        "\n",
        "#print(distancia(X_train))\n",
        "\n",
        "\n",
        "k = 5\n",
        "\n",
        "#! Traten de no dejar codigo y celdas enteras comentadas\n",
        "# x = prenda que quiero clasificar\n",
        "# X_train = base de datos de prendas\n",
        "# y_train = clasificaciones de las prendas de X_train\n",
        "# def KNN(k,x,X_train,y_train):\n",
        "\n",
        "#     #print(matriz_distancia.shape)\n",
        "#     distancias = {'index': [], 'dist': []}\n",
        "#     for i in range(0,len(X_train)-1):\n",
        "#       distancias['index'].append(i)\n",
        "#       distancias['dist'].append(matriz_distancia[i][len(matriz_distancia)-1])\n",
        "\n",
        "#     # Obtengo un array con los k índices (en X_train) de las menores distancias\n",
        "\n",
        "#     k_vecinos_cercanos = np.argsort(distancias['dist'])[0:k-1]#,order=['dist','index'])[0:k-1]\n",
        "#     # k_min_distancias = np.array(distancias['dist'])[k_min_distancias]\n",
        "#     # Indexo y_train en estos k índices para obtener qué tipo de prenda son los k vecinos más cercanos\n",
        "#     prendas_cercanas = []\n",
        "#     for i in k_vecinos_cercanos:\n",
        "#       prendas_cercanas.append(y_train[i])\n",
        "#     # Veo cuál tipo de prenda se repite más en los k vecinos más cercanos\n",
        "#     prediction = st.mode(prendas_cercanas)[0]\n",
        "#     return prediction\n",
        "\n",
        "def KNN(k,distancias_a_x,y_train):\n",
        "  # indices = np.arange(0,len(distancias_a_x)-1)\n",
        "  # distancias = {'index': indices, 'dist': distancias_a_x}\n",
        "  # Obtengo un array con los k índices en X_train de las menores distancias\n",
        "  #k_vecinos_cercanos = np.argsort(distancias['dist'])[0:k-1]\n",
        "  k_vecinos_cercanos = np.argsort(distancias_a_x)[0:k-1]\n",
        "  prendas_cercanas = []\n",
        "  for i in k_vecinos_cercanos: #! Numpy permite indexar con lista de indices, se pueden ahorrar este for\n",
        "    prendas_cercanas.append(y_train[i])\n",
        "  # Veo cuál tipo de prenda se repite más en los k vecinos más cercanos\n",
        "  prediction = st.mode(prendas_cercanas)[0]\n",
        "  return prediction\n",
        "\n",
        "def exactitud(k,X_train,y_train,X_dev,y_dev):\n",
        "  # Creo la matriz de distancias\n",
        "  X_train_tmp = np.concatenate((X_train,X_dev),axis=0)\n",
        "  # Me quedo solo con la parte de la matriz que compara los elementos de X_dev con los de X_train\n",
        "  matriz_distancia = distancia(X_train_tmp)[:len(X_dev)-1,len(X_dev):] #! Cuidado que se estan quedando un pedazo incorrecto de la matriz como distancias\n",
        "\n",
        "\n",
        "  aciertos = []\n",
        "  for i in range(len(X_dev)-1): #! Traten de eliminar este for\n",
        "    prediction = KNN(k,matriz_distancia[i],y_train)\n",
        "    # print(prediction)\n",
        "\n",
        "    if prediction == y_dev[i]:\n",
        "      aciertos.append(1)\n",
        "    else:\n",
        "      aciertos.append(0)\n",
        "  return np.mean(aciertos) # Devuelvo el promedio del vector de aciertos\n",
        "\n",
        "print(exactitud(k,X_train,y_train,X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bSES-vwQRVv"
      },
      "source": [
        "## Metodo de la potencia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTXvXQ1tfBzO"
      },
      "source": [
        "Para poder ejecutar el método de la potencia más eficientemente se realiza una implementación en C++ utilizando la libreria `eigen`.\n",
        "Se instalan las dependencias necesarias,  se implementa el algoritmo y se compila utilizando `g++` con el flag `-O3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEf-2BCZQd69",
        "outputId": "c00ec557-25cd-42e2-f4a0-63e06f9e8e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libeigen3-dev is already the newest version (3.4.0-2ubuntu2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://gitlab.com/libeigen/eigen.git\n",
        "!apt-get install libeigen3-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDHREH8_Qier",
        "outputId": "6eaea757-d02d-46f1-d37a-360c6ce2991b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eigen_test.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file eigen_test.cpp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "#include <eigen3/Eigen/Dense>\n",
        "#include <utility>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <eigen3/Eigen/Dense>\n",
        "\n",
        "using Eigen::MatrixXf;\n",
        "using Eigen::VectorXf;\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "pair<Eigen::VectorXf,float> metpot(const Eigen::MatrixXf& B, Eigen::VectorXf x_0, int niter, float epsilon){\n",
        "    double res = 0;\n",
        "    int j = 1;\n",
        "    Eigen::VectorXf v = std::move(x_0); //#! Generenlo al azar aca mismo en vez de pasarlo como parametro\n",
        "    Eigen::VectorXf vant = v;\n",
        "    Eigen::RowVectorXf vtrans = v.transpose();\n",
        "    for(int i = 0; i<niter; i++){\n",
        "        v = B*v;\n",
        "        v.normalize();\n",
        "        vtrans = v.transpose(); //#!  No es necesario calcularlo en todas las iteraciones\n",
        "        res = (vtrans*B)*v; //#! No es necesario calcularlo en todas las iteraciones\n",
        "        j++;\n",
        "        if((v - vant).lpNorm<Eigen::Infinity>() < epsilon){\n",
        "            break;\n",
        "        }\n",
        "        vant = v;\n",
        "    }\n",
        "    //cout<<v;\n",
        "    //printf(\"pare en la iter %d \\n\", j);\n",
        "    return make_pair(v,res);\n",
        "\n",
        "}\n",
        "\n",
        "vector<pair<Eigen::VectorXf,float>> metpotdefl(Eigen::MatrixXf B, const Eigen::VectorXf& x_0, int niter, float epsilon){\n",
        "    vector<pair<Eigen::VectorXf,float>> res;\n",
        "    Eigen::MatrixXf C = std::move(B);\n",
        "    for(int i = 0; i<C.cols(); i++){\n",
        "        res.push_back(metpot(C,x_0,niter,epsilon));\n",
        "        Eigen::VectorXf vnormal = res[i].first;\n",
        "        Eigen::RowVectorXf vtrans = res[i].first.transpose();\n",
        "        Eigen::MatrixXf vgrande = vnormal * vtrans;\n",
        "        vgrande = (res[i].second*vgrande);\n",
        "        C = C - vgrande;\n",
        "    }\n",
        "    return res;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    if (argc != 3) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_file output_file\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    const char* input_file = argv[1];\n",
        "    const char* output_file = argv[2];\n",
        "\n",
        "    std::ifstream fin(input_file);\n",
        "    if (!fin.is_open()) {\n",
        "        std::cerr << \"Error: could not open input file \" << input_file << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Read matrix and vector from file\n",
        "    int nrows, ncols;\n",
        "    fin >> nrows >> ncols;\n",
        "\n",
        "    MatrixXf A(nrows, ncols);\n",
        "    for (int i = 0; i < nrows; i++) {\n",
        "        for (int j = 0; j < ncols; j++) {\n",
        "            fin >> A(i, j);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    VectorXf b(ncols);\n",
        "    for (int i = 0; i < ncols; i++) {\n",
        "        fin >> b(i);\n",
        "    }\n",
        "\n",
        "    fin.close();\n",
        "\n",
        "    b.normalize();\n",
        "\n",
        "    // Perform matrix-vector multiplication\n",
        "    vector<pair<Eigen::VectorXf,float>> c = metpotdefl(A,b,10000,1e-7);\n",
        "    cout<<A<<endl;\n",
        "    cout<<b<<endl;\n",
        "\n",
        "    // Write result to output file\n",
        "    std::ofstream fout(output_file);\n",
        "    if (!fout.is_open()) {\n",
        "        std::cerr << \"Error: could not open output file \" << output_file << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "        for(int i = 0; i<c.size(); i++){\n",
        "            fout<<c[i].first.transpose()<<endl;\n",
        "            //fout<<c[i].second<<endl; //autovalor <- sacar para pca\n",
        "        }\n",
        "\n",
        "\n",
        "    fout.close();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8YmwoumcrpQE"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "g++ -O3 eigen_test.cpp -o out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtmrJkybrqCm"
      },
      "outputs": [],
      "source": [
        "#np.loadtxt('output_data.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aL8BNR7MrNvZ"
      },
      "outputs": [],
      "source": [
        "#A = np.array([[1, 2, 3], [2, 5, 6], [3, 6, 9]], dtype=np.float64)\n",
        "#b = np.array([1, 0, 0], dtype=np.float64)\n",
        "\n",
        "#b = np.zeros(len(C))\n",
        "#b[0] = 1\n",
        "#print(C.shape)\n",
        "#!rm input_data.txt\n",
        "#with open('input_data.txt','a') as f:\n",
        "#    f.write(f\"{C.shape[0]} {C.shape[1]}\\n\")\n",
        "#    np.savetxt(f,C, newline=\"\\n\")\n",
        "#    np.savetxt(f,b.reshape(1,-1), fmt='%1.3f', newline=\"\\n\")\n",
        "#!cat input_data.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fdSGGsCfGnYo"
      },
      "outputs": [],
      "source": [
        "def PCA(C):\n",
        "  b = np.zeros(len(C))\n",
        "  b[0] = 1\n",
        "  print(C.shape)\n",
        "  !rm input_data.txt\n",
        "  with open('input_data.txt','a') as f:\n",
        "      f.write(f\"{C.shape[0]} {C.shape[1]}\\n\")\n",
        "      np.savetxt(f,C, newline=\"\\n\")\n",
        "      np.savetxt(f,b.reshape(1,-1), fmt='%1.3f', newline=\"\\n\")\n",
        "  #!cat input_data.txt\n",
        "  !./out input_data.txt output_data.txt\n",
        "  array_autovectores = np.fromfile('output_data.txt')\n",
        "  array_autovectores = array_autovectores.T\n",
        "  return array_autovectores\n",
        "#PCA(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DjhyDwXl9n9"
      },
      "outputs": [],
      "source": [
        "X_train_np = np.array(X_train)\n",
        "y_train_np = np.array(y_train)\n",
        "split_X = np.array_split(X_train_np,5,axis=0)\n",
        "split_Y = np.array_split(y_train_np,5)\n",
        "for i in range(0, len(split_X)-1):\n",
        "  X_dev_temp = split_X[i]\n",
        "  y_dev_temp = split_Y[i]\n",
        "  X_train_temp = np.concatenate([split_X[j] for j in range(len(split_X)) if j != i])\n",
        "  y_train_temp = np.concatenate([split_Y[j] for j in range(len(split_Y)) if j != i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KBBlyHFxX74L"
      },
      "outputs": [],
      "source": [
        "def cross_validation_autovectores():\n",
        "  # Creo las 5 particiones de ambos arrays\n",
        "  X_train_np = np.array(X_train)\n",
        "  y_train_np = np.array(y_train)\n",
        "  split_X = np.array_split(X_train_np,5,axis=0)\n",
        "  split_Y = np.array_split(y_train_np,5)\n",
        "  maxima_exactitud = 0\n",
        "  optimos = (-1,-1)\n",
        "  for i in range(0, len(split_X)-1):\n",
        "    X_dev_temp = split_X[i]\n",
        "    y_dev_temp = split_Y[i]\n",
        "    X_train_temp = np.array([])\n",
        "    y_train_temp = np.array([])\n",
        "    X_train_temp = np.concatenate([split_X[j] for j in range(len(split_X)) if j != i])\n",
        "    y_train_temp = np.concatenate([split_Y[j] for j in range(len(split_Y)) if j != i])\n",
        "\n",
        "    # Matriz de covarianza\n",
        "    # print(X.shape, X.T.shape)\n",
        "    C = (X_train_temp.T @ X_train_temp) / (len(X_train_temp)-1) #!  Falta centrar, hagan funciones que calculen estas cosas\n",
        "    PCA(C)\n",
        "    V = np.fromfile('output_data.txt', sep=' ').reshape(784, 784).T\n",
        "    for k in range(1,5):\n",
        "      for p in range (1,784,25):\n",
        "        X_hat_train = X_train_temp @ V[:,:p]\n",
        "        X_hat_dev = X_dev_temp @ V[:,:p]\n",
        "        res = exactitud(k,X_hat_train,y_train_temp,X_hat_dev,y_dev_temp)\n",
        "        if res > maxima_exactitud:\n",
        "          maxima_exactitud = res\n",
        "          optimos = (k,p)\n",
        "  return optimos\n",
        "\n",
        "# cross_validation_autovectores()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XBLT8hvlkmW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "9877a9a1-918b-4ce8-e12b-a5b1f6ff2cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 784)\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'output_data.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-27-4045065548.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexactitud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_hat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_hat_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-27-4045065548.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moptimos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_autovectores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-26-3942168378.py\u001b[0m in \u001b[0;36mcross_validation_autovectores\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# print(X.shape, X.T.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_train_temp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#!  Falta centrar, hagan funciones que calculen estas cosas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-24-378900260.py\u001b[0m in \u001b[0;36mPCA\u001b[0;34m(C)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#!cat input_data.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./out input_data.txt output_data.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0marray_autovectores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_data.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0marray_autovectores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_autovectores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0marray_autovectores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output_data.txt'"
          ]
        }
      ],
      "source": [
        "def test():\n",
        "    optimos = cross_validation_autovectores()\n",
        "    k = optimos[0]\n",
        "    p = optimos[1]\n",
        "    C = (X_train.T @ X_train) / (len(X_train)-1)\n",
        "    PCA(C)\n",
        "\n",
        "    V = np.fromfile('output_data.txt', sep=' ').reshape(784, 784).T\n",
        "    X_hat_train = X_train @ V[:,:p]\n",
        "    X_hat_test = X_test @ V[:,:p]\n",
        "    return exactitud(k,X_hat_train,y_train,X_hat_test,y_test)\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD9KUk6cjTJ8"
      },
      "source": [
        "## Convergencia del Método de la potencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqmOqmL5_7cE"
      },
      "outputs": [],
      "source": [
        "%%file eigen_test2.cpp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "#include <eigen3/Eigen/Dense>\n",
        "#include <utility>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <eigen3/Eigen/Dense>\n",
        "#include <tuple>\n",
        "\n",
        "using Eigen::MatrixXf;\n",
        "using Eigen::VectorXf;\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "tuple<Eigen::VectorXf,float,int,float> metpot(const Eigen::MatrixXf& B, Eigen::VectorXf x_0, int niter, float epsilon){\n",
        "    double res = 0;\n",
        "    int j = 1;\n",
        "    Eigen::VectorXf v = std::move(x_0);\n",
        "    Eigen::VectorXf vant = v;\n",
        "    Eigen::RowVectorXf vtrans = v.transpose();\n",
        "    for(int i = 0; i<niter; i++){\n",
        "        v = B*v;\n",
        "        v.normalize();\n",
        "        vtrans = v.transpose();\n",
        "        res = (vtrans*B)*v;\n",
        "        j++;\n",
        "        if((v - vant).lpNorm<Eigen::Infinity>() < epsilon){\n",
        "            break;\n",
        "        }\n",
        "        vant = v;\n",
        "    }\n",
        "    //cout<<v;\n",
        "    //printf(\"pare en la iter %d \\n\", j);\n",
        "    float error = (B*v - res*v).norm();\n",
        "    return make_tuple(v,res,j,error);\n",
        "\n",
        "}\n",
        "\n",
        "vector<tuple<Eigen::VectorXf,float,int,float>> metpotdefl(Eigen::MatrixXf B, const Eigen::VectorXf& x_0, int niter, float epsilon){\n",
        "    vector<tuple<Eigen::VectorXf,float,int,float>> res;\n",
        "    Eigen::MatrixXf C = std::move(B);\n",
        "    for(int i = 0; i<C.cols(); i++){\n",
        "        res.push_back(metpot(C,x_0,niter,epsilon));\n",
        "        Eigen::VectorXf vnormal = get<0>(res[i]);\n",
        "        Eigen::RowVectorXf vtrans = get<0>(res[i]).transpose();\n",
        "        Eigen::MatrixXf vgrande = vnormal * vtrans;\n",
        "        vgrande = (get<1>(res[i])*vgrande);\n",
        "        C = C - vgrande;\n",
        "    }\n",
        "    return res;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    if (argc != 3) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_file output_file\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    const char* input_file = argv[1];\n",
        "    const char* output_file = argv[2];\n",
        "\n",
        "    std::ifstream fin(input_file);\n",
        "    if (!fin.is_open()) {\n",
        "        std::cerr << \"Error: could not open input file \" << input_file << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Read matrix and vector from file\n",
        "    int nrows, ncols;\n",
        "    fin >> nrows >> ncols;\n",
        "\n",
        "    MatrixXf A(nrows, ncols);\n",
        "    for (int i = 0; i < nrows; i++) {\n",
        "        for (int j = 0; j < ncols; j++) {\n",
        "            fin >> A(i, j);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    VectorXf b(ncols);\n",
        "    for (int i = 0; i < ncols; i++) {\n",
        "        fin >> b(i);\n",
        "    }\n",
        "\n",
        "    fin.close();\n",
        "\n",
        "    b.normalize();\n",
        "\n",
        "    // Perform matrix-vector multiplication\n",
        "    vector<tuple<Eigen::VectorXf,float,int,float>> c = metpotdefl(A,b,10000,1e-7);\n",
        "\n",
        "\n",
        "    // Write result to output file\n",
        "    std::ofstream fout(output_file);\n",
        "    if (!fout.is_open()) {\n",
        "        std::cerr << \"Error: could not open output file \" << output_file << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "        for(int i = 0; i<c.size(); i++){\n",
        "            fout<<get<0>(c[i]).transpose()<<endl;\n",
        "            fout<<get<1>(c[i])<<endl;\n",
        "            fout<<get<2>(c[i])<<endl;\n",
        "            fout<<get<3>(c[i])<<endl;\n",
        "        }\n",
        "\n",
        "\n",
        "    fout.close();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "/*int main()\n",
        "{\n",
        "//\n",
        "//\n",
        "    Eigen::VectorXf x = Eigen::VectorXf::Zero(150);\n",
        "\n",
        "    // Asignar 1 al primer elemento\n",
        "    x(0) = 1;\n",
        "\n",
        "    x.normalize();\n",
        "\n",
        "\n",
        "    Eigen::VectorXf v(150);\n",
        "    v.setRandom();\n",
        "    v.normalize();\n",
        "\n",
        "    Eigen::RowVectorXf vtrans = v.transpose();\n",
        "\n",
        "\n",
        "    Eigen::VectorXf diag(150);\n",
        "    diag<< 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "            21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n",
        "            41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
        "            61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
        "            81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100,\n",
        "            101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
        "            121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
        "            141, 142, 143, 144, 145, 146, 147, 148, 149, 150;\n",
        "    Eigen::DiagonalMatrix<float, Eigen::Dynamic> matDiag(diag);\n",
        "\n",
        "    Eigen::MatrixXf identityMatrix = Eigen::MatrixXf::Identity(150,150);\n",
        "\n",
        "\n",
        "    Eigen::MatrixXf Q = identityMatrix - 2*v*vtrans;\n",
        "    Eigen::MatrixXf Qtrans = Q.transpose();\n",
        "    Eigen::MatrixXf A = Qtrans*matDiag*Q;\n",
        "\n",
        "    vector<pair<Eigen::VectorXf,float>> res = metpotdefl(A,x,10000,1e-7);\n",
        "\n",
        "\n",
        "    for(int j = 0; j<150; j++){\n",
        "        printf(\"inicio eigen %d \\n\",j);\n",
        "        cout<<res[j].first<<endl;\n",
        "        cout<<res[j].second<<endl;\n",
        "        printf(\"fin eigen %d \\n\",j);\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "*/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI83vHtVRehz"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "#Esto es si queres ejecutar el segundo main del codigo de arriba, el cual hace el test de una matriz de Householder random con autovalores 1,..,150\n",
        "# g++ -Ieigen eigen_types_test.cpp -o out\n",
        "g++ -O3 eigen_types_test2.cpp -o out\n",
        "./out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRQBKrQ5ql8v"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "#esto es para compilar el primer main que escribe el output en archivos con el formato vi, λi, #iter, error (una linea por resultado)\n",
        "g++ -O3 eigen_test2.cpp -o out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj5WHQqeBTZA"
      },
      "outputs": [],
      "source": [
        "def test_error():\n",
        "  CANTIDAD_ITERACIONES = 100\n",
        "  b = np.array([1, 0, 0, 0, 0], dtype=np.float64)\n",
        "\n",
        "  #! Traten de hacer las cosas usando listas y nombres mas representativos\n",
        "  epsilon_list = []\n",
        "  error_listv1 = []\n",
        "  error_listv2 = []\n",
        "  error_listv3 = []\n",
        "  error_listv4 = []\n",
        "  error_listv5 = []\n",
        "\n",
        "  iter_listv1 = []\n",
        "  iter_listv2 = []\n",
        "  iter_listv3 = []\n",
        "  iter_listv4 = []\n",
        "  iter_listv5 = []\n",
        "\n",
        "\n",
        "  desv_stdv1fin = []\n",
        "  desv_stdv2fin = []\n",
        "  desv_stdv3fin = []\n",
        "  desv_stdv4fin = []\n",
        "  desv_stdv5fin = []\n",
        "\n",
        "  # desv_stdv1 = []\n",
        "  # desv_stdv2 = []\n",
        "  # desv_stdv3 = []\n",
        "  # desv_stdv4 = []\n",
        "  # desv_stdv5 = []\n",
        "  #pasos_list= []\n",
        "  promv1 = 0\n",
        "  promv2 = 0\n",
        "  promv3 = 0\n",
        "  promv4 = 0\n",
        "  promv5 = 0\n",
        "\n",
        "  promv1it = 0\n",
        "  promv2it = 0\n",
        "  promv3it = 0\n",
        "  promv4it = 0\n",
        "  promv5it = 0\n",
        "  for epsilon in np.logspace(-4, 0, num=10):\n",
        "    epsilon_list.append(epsilon)\n",
        "    promv1 = 0\n",
        "    promv2 = 0\n",
        "    promv3 = 0\n",
        "    promv4 = 0\n",
        "    promv5 = 0\n",
        "    promv1it = 0\n",
        "    promv2it = 0\n",
        "    promv3it = 0\n",
        "    promv4it = 0\n",
        "    promv5it = 0\n",
        "    desv_stdv1fin = []\n",
        "    desv_stdv2fin = []\n",
        "    desv_stdv3fin = []\n",
        "    desv_stdv4fin = []\n",
        "    desv_stdv5fin = []\n",
        "\n",
        "    for i in range(0, CANTIDAD_ITERACIONES):\n",
        "\n",
        "      D = np.diag([10, 10-epsilon, 5, 2, 1])\n",
        "\n",
        "      v = np.random.rand(D.shape[0])\n",
        "      #print(v)\n",
        "\n",
        "      v = v / np.linalg.norm(v)\n",
        "      #print(v)\n",
        "\n",
        "    # Matriz de Householder\n",
        "      v = v.reshape(-1, 1)\n",
        "      B = np.eye(D.shape[0]) - 2 * (v @ np.transpose(v))\n",
        "      #print(v @ np.transpose(v))\n",
        "\n",
        "    # Matriz a diagonalizar\n",
        "      matriz_hh =  np.transpose(B) @ D @ B\n",
        "\n",
        "      #print(matriz_hh)\n",
        "\n",
        "      !rm input_data.txt\n",
        "      with open('input_data.txt','a') as f:\n",
        "          f.write(f\"{matriz_hh.shape[0]} {matriz_hh.shape[1]}\\n\")\n",
        "          np.savetxt(f, matriz_hh, newline=\"\\n\")\n",
        "          np.savetxt(f ,b.reshape(1,-1), fmt='%1.3f', newline=\"\\n\")\n",
        "      !./out input_data.txt f\"output_data_{epsilon}\".txt\n",
        "\n",
        "      with open(f'foutput_data_{epsilon}.txt') as f:\n",
        "        txt = str.split(f.read(), '\\n')\n",
        "        promv1 += float(txt[3])\n",
        "        # promv2 += float(txt[7])\n",
        "        # promv3 += float(txt[11])\n",
        "        # promv4 += float(txt[15])\n",
        "        # promv5 += float(txt[19])\n",
        "        promv1it += float(txt[2])\n",
        "        # promv2it += float(txt[6])\n",
        "        # promv3it += float(txt[10])\n",
        "        # promv4it += float(txt[14])\n",
        "        # promv5it += float(txt[18])\n",
        "        desv_stdv1fin.append(float(txt[3]))\n",
        "        # desv_stdv2fin.append(float(txt[7]))\n",
        "        # desv_stdv3fin.append(float(txt[11]))\n",
        "        # desv_stdv4fin.append(float(txt[15]))\n",
        "        # desv_stdv5fin.append(float(txt[19]))\n",
        "\n",
        "    error_listv1.append(promv1/CANTIDAD_ITERACIONES)\n",
        "    # error_listv2.append(promv2/CANTIDAD_ITERACIONES)\n",
        "    # error_listv3.append(promv3/CANTIDAD_ITERACIONES)\n",
        "    # error_listv4.append(promv4/CANTIDAD_ITERACIONES)\n",
        "    # error_listv5.append(promv5/CANTIDAD_ITERACIONES)\n",
        "\n",
        "    iter_listv1.append(promv1it/CANTIDAD_ITERACIONES)\n",
        "    # iter_listv2.append(promv2it/CANTIDAD_ITERACIONES)\n",
        "    # iter_listv3.append(promv3it/CANTIDAD_ITERACIONES)\n",
        "    # iter_listv4.append(promv4it/CANTIDAD_ITERACIONES)\n",
        "    # iter_listv5.append(promv5it/CANTIDAD_ITERACIONES)\n",
        "\n",
        "\n",
        "\n",
        "  return [epsilon_list,error_listv1,iter_listv1,desv_stdv1fin]\n",
        "\n",
        "data = test_error()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDFyNf__Vx_O"
      },
      "outputs": [],
      "source": [
        "\n",
        "std_errorv1 = np.std(data[3])\n",
        "# std_errorv2 = np.std(data[12])\n",
        "# std_errorv3 = np.std(data[13])\n",
        "# std_errorv4 = np.std(data[14])\n",
        "# std_errorv5 = np.std(data[15])\n",
        "\n",
        "plt.yscale('log') # escala log que muestra...?\n",
        "plt.xscale('log') # escala log que muestra los epsilons tomados espaciados logaritmicamente\n",
        "plt.xlabel('ɛ')\n",
        "plt.ylabel('||Avi-λvi||2')\n",
        "\n",
        "plt.plot(data[0], data[1], '.k',label=\"v1\",color=\"red\")\n",
        "plt.plot(data[0], data[1], '.k',label=\"v1\",color=\"red\")\n",
        "#plt.fill_between(data[0], data[1] + std_errorv1, data[1] - std_errorv1, alpha = 0.2, color = 'red')\n",
        "\n",
        "# plt.plot(data[0], data[2],'.k',label=\"v2\",color=\"green\")\n",
        "# plt.fill_between(data[0], data[2] + std_errorv2, data[2] - std_errorv2, alpha = 0.2, color = 'green')\n",
        "\n",
        "\n",
        "# plt.plot(data[0], data[3],'.k',label=\"v3\",color=\"blue\")\n",
        "# plt.fill_between(data[0], data[3] + std_errorv3, data[3] - std_errorv3, alpha = 0.2, color = 'blue')\n",
        "\n",
        "# plt.plot(data[0], data[4],'.k',label=\"v4\",color=\"yellow\")\n",
        "# plt.fill_between(data[0], data[4] + std_errorv4, data[4] - std_errorv4, alpha = 0.2, color = 'yellow')\n",
        "\n",
        "\n",
        "# plt.plot(data[0], data[5],'.k',label=\"v5\",color=\"black\")\n",
        "# plt.fill_between(data[0], data[5] + std_errorv5, data[5] - std_errorv5, alpha = 0.2, color = 'black')\n",
        "\n",
        "#plt.margins(x=0, y=10)\n",
        "plt.legend(loc=\"upper right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3PS0OGJ4QzH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "plt.yscale('log') # escala log que muestra...?\n",
        "plt.xscale('log') # escala log que muestra los epsilons tomados espaciados logaritmicamente\n",
        "plt.xlabel('ɛ')\n",
        "plt.ylabel('#iteraciones')\n",
        "\n",
        "plt.plot(data[0], data[6], '.k',label=\"v1\",color=\"red\")\n",
        "plt.plot(data[0], data[7],'.k',label=\"v2\",color=\"green\")\n",
        "plt.plot(data[0], data[8],'.k',label=\"v3\",color=\"blue\")\n",
        "plt.plot(data[0], data[9],'.k',label=\"v4\",color=\"yellow\")\n",
        "plt.plot(data[0], data[10],'.k',label=\"v5\",color=\"black\")\n",
        "plt.legend(loc=\"upper right\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}